# Author-Profiling
Репозиторий для оценки моделей по задаче авторского профилирования по полу и возрасту.

В работу входит 3 части:
  - набор данных для обучения и оценки моделей;
  - скрипт для вычисления F1 метрики оценки моделей;
  - набор моделей из работы ...;

## Установка
Список необходимых пакетов и версий приведён в файле requirements.txt.
Для скачивания весов Graph Attention Model (GAModel) и подготовленного оригинального корпуса необходимо установить git lfs.
Для работы Graph Attention модели необходимо поставить tensorflow версии 2.4.1, для работы BERT необходимо поставить torch версии 1.7.1.

После устанвоки stanza необходимо скачать модели для русского языка, для этого запустить python и выполнить команды:
```python
import stanza
stanza.download("ru")
exit()
```

## 1. Данные
Корпус представляет собой набор текстов с известными метками, относящимися к профилю автора:
  - пол;
  - возрастная группа;
  - текст написан с или без намеренного искажения стиля, возраста или пола;

Дополнительно для части документов известно, что текст написан с одним из искажений:
  - от противоположенного пола;
  - от лица сильно старше;
  - от лица сильно моложе;
  - с использованием нестандартного для себя стиля написания;

Набор данных и его детальное описание доступны на Huggingface [sagteam/author_profiling](https://huggingface.co/datasets/sagteam/author_profiling).

## 2. Скрипт оценки
Сам скрипт в src/data/evaluate.py

## 3. Модели
В работе рассматривались два типа моделей: Graph Attention Model и BERT.
Graph Attention Model использует в качестве признаков морфологию слов и граф синтаксического разбора.
Для каждого типа выходной метки (пол, возрастная группа, наличие имитации и т.д.) строится отдельная модель.

### 3.1 Модель GAModel

**Обучение и оценка модели**
1. Подготовка данных, для этого надо перейти в папку `data` и запустить скрипт `prepare_full_ds.sh`;
2. Перейти в папку src и запустить скрипт `run_ray_pbt_v2.sh` (дал лучшие результаты для GAModel);

**Готовые веса**
Для получения выходов уже обученных моделей Graph Attention Model для тестового множества надо:
1. распаковать лучшие веса моделей из архива `gamodel_best_weights.tar.gz` командой `tar -xzf gamodel_best_weights.tar.gz`;
2. распаковать уже подготовленный корпус, из архива `orig_vectorized.tar.gz` в папку `data/orig/vectorized/` командой `cd data/orig/ && tar -xzf orig_vectorized.tar.gz`;
3. запустить скрипт `src/get_outputs_best_models.sh` - результаты для каждой модели будут сохранены в папке RUN\_NAME\_outputs, где RUN\_NAME - название модели из списка: "ga\_hpo\_v1", "ga\_pbt\_v2", "gamodel\_v3\_no\_synt", "gamodel\_v4\_x\_const".

### 3.2 Модель BERT
В папке `notebooks` есть блокнот `RuBERT_models_ds_for_grant.ipynb` для запуска модели на основе RuBERT или tiny-rubert, по стандарту там стоит конфигурация для отладки, для обучения на полном корпусе надо установить переменную SMALL_DS=False и в ячейке 8 с конфигурациями моделей закомментировать конфигурацию для отладки и раскомментировать нужную для запуска.

### 3.3 LinearSVC + TFIDF и Dummy модели
В папке `notebooks` есть блокнот `Dummy_models_ds_for_grant.ipynb` - для получения базовых точностей надо его запустить.

## Citation Information
If you have found our results helpful in your work, feel free to cite our publication. 
```
@article{сбоев2022сравнение,
  title={СРАВНЕНИЕ ТОЧНОСТЕЙ МЕТОДОВ НА ОСНОВЕ ЯЗЫКОВЫХ И ГРАФОВЫХ НЕЙРОСЕТЕВЫХ МОДЕЛЕЙ ДЛЯ ОПРЕДЕЛЕНИЯ ПРИЗНАКОВ АВТОРСКОГО ПРОФИЛЯ ПО ТЕКСТАМ НА РУССКОМ ЯЗЫКЕ},
  author={Сбоев, АГ and Молошников, ИА and Рыбка, РБ and Наумов, АВ and Селиванов, АА},
  journal={Вестник Национального исследовательского ядерного университета МИФИ},
  volume={10},
  number={6},
  pages={529--539},
  year={2021},
  publisher={Общество с ограниченной ответственностью МАИК "Наука/Интерпериодика"}
}
```
